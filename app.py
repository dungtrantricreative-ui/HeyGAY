import google.generativeai as genai
import gradio as gr
import os
import time

# --- C·∫•u h√¨nh API Key ---
# Render s·∫Ω cung c·∫•p API Key qua bi·∫øn m√¥i tr∆∞·ªùng.
api_key = os.environ.get("GEMINI_API_KEY")
if not api_key:
    raise ValueError("L·ªói: Vui l√≤ng ƒë·∫∑t GEMINI_API_KEY trong bi·∫øn m√¥i tr∆∞·ªùng c·ªßa Render.")
genai.configure(api_key=api_key)

# --- Kh·ªüi t·∫°o m√¥ h√¨nh ---
print("ƒêang kh·ªüi t·∫°o m√¥ h√¨nh HEYGAY...")
model = genai.GenerativeModel('gemini-2.5-flash')
print("Kh·ªüi t·∫°o m√¥ h√¨nh th√†nh c√¥ng!")

# --- H√†m logic ch√≠nh c·ªßa Chatbot ---
def gemini_chatbot_response(user_text, file_obj, chat_history):
    parts = []
    
    if file_obj is not None:
        try:
            print(f"ƒêang x·ª≠ l√Ω t·ªáp: {file_obj.name}")
            uploaded_file = genai.upload_file(path=file_obj.name)
            
            while uploaded_file.state.name == "PROCESSING":
                print("T·ªáp ƒëang ƒë∆∞·ª£c x·ª≠ l√Ω, vui l√≤ng ƒë·ª£i...")
                time.sleep(2)
                uploaded_file = genai.get_file(uploaded_file.name)

            if uploaded_file.state.name != "ACTIVE":
                raise ValueError(f"X·ª≠ l√Ω t·ªáp th·∫•t b·∫°i v·ªõi tr·∫°ng th√°i: {uploaded_file.state.name}")
            
            print(f"T·ªáp ƒë√£ ·ªü tr·∫°ng th√°i ACTIVE: {uploaded_file.name}")
            parts.append(uploaded_file)
            
        except Exception as e:
            chat_history.append((user_text, f"L·ªói khi x·ª≠ l√Ω t·ªáp: {e}"))
            return "", None, chat_history

    if user_text:
        parts.append(user_text)

    if not parts:
        chat_history.append(("", "Vui l√≤ng nh·∫≠p tin nh·∫Øn ho·∫∑c t·∫£i l√™n m·ªôt t·ªáp."))
        return "", None, chat_history

    try:
        print("ƒêang g·ª≠i y√™u c·∫ßu ƒë·∫øn HEYGAY...")
        response = model.generate_content(parts)
        model_response = response.text
        print("ƒê√£ nh·∫≠n ph·∫£n h·ªìi t·ª´ Gemini.")
    except Exception as e:
        model_response = f"R·∫•t ti·∫øc, ƒë√£ x·∫£y ra l·ªói: {e}"

    chat_history.append((user_text or "[ƒê√£ g·ª≠i m·ªôt t·ªáp]", model_response))
    return "", None, chat_history

# --- Giao di·ªán Gradio ---
with gr.Blocks(theme=gr.themes.Soft(), css="footer {display: none !important}") as demo:
    gr.Markdown("# ü§ñ Chatbot ƒêa ph∆∞∆°ng th·ª©c v·ªõi ")
    gr.Markdown("Tr√≤ chuy·ªán b·∫±ng vƒÉn b·∫£n ho·∫∑c t·∫£i l√™n h√¨nh ·∫£nh, √¢m thanh, video ƒë·ªÉ b·∫Øt ƒë·∫ßu.")

    # B·∫°n c·∫ßn c√≥ 2 file ·∫£nh n√†y trong th∆∞ m·ª•c d·ª± √°n
    chatbot = gr.Chatbot(label="Cu·ªôc tr√≤ chuy·ªán", height=600, avatar_images=("user.png", "bot.png"))

    with gr.Row():
        file_upload = gr.File(label="T·∫£i l√™n t·ªáp (·∫£nh, √¢m thanh, video)", file_count="single")
        text_input = gr.Textbox(label="Nh·∫≠p tin nh·∫Øn c·ªßa b·∫°n...", placeholder="V√≠ d·ª•: T√≥m t·∫Øt n·ªôi dung trong video n√†y cho t√¥i.", scale=3)

    send_btn = gr.Button("G·ª≠i", variant="primary")

    send_btn.click(
        fn=gemini_chatbot_response,
        inputs=[text_input, file_upload, chatbot],
        outputs=[text_input, file_upload, chatbot]
    )
    text_input.submit(
        fn=gemini_chatbot_response,
        inputs=[text_input, file_upload, chatbot],
        outputs=[text_input, file_upload, chatbot]
    )

# --- Kh·ªüi ch·∫°y ·ª©ng d·ª•ng ---
# Ch·∫°y server tr√™n 0.0.0.0 ƒë·ªÉ Render c√≥ th·ªÉ truy c·∫≠p
print("ƒêang kh·ªüi ch·∫°y giao di·ªán Gradio tr√™n server...")
demo.launch(server_name="0.0.0.0", server_port=7860)
